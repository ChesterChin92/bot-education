{"nbformat_minor": 0, "cells": [{"source": "## Entity Linking with Microsoft Cognitive Services Entity Linking Intelligence Service API\n\nEntity Linking is a natural language processing tool to help analyzing text for your application. Entity Linking recognize a named-entity from given text and aligning a textual mention of the entity to an appropriate entry in a knowledge base. -*from ELIS API Reference*", "cell_type": "markdown", "metadata": {}}, {"source": "#### For python 2 and 3 compatibility we have a few imports", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "import json\n\n# Import compatibility libraries (python 2/3 support)\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\n# Python 3\ntry:\n    from urllib.request import urlopen, Request\n    from urllib.parse import urlparse, urlencode\n    from http.client import HTTPSConnection\n# Python 2.7\nexcept ImportError:\n    from urlparse import urlparse\n    from urllib import urlencode\n    from urllib2 import Request, urlopen\n    from httplib import HTTPSConnection ", "outputs": [], "metadata": {"collapsed": false}}, {"source": "**Load our configuration file (just has subscription key as of now)**", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "f = urlopen('url here to gist with keys') # gist will be keys as json\nkeys = f.read()\n\n# process json\nkeys = json.load(keys)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "**Load our text data from a file**\n\nELIS expects it in UTF-8 encoded plain text.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "f = urlopen('https://raw.githubusercontent.com/michhar/bot-education/master/CognitiveServices/Samples/KNOWLEDGE_API/python/sample_text.txt')", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "# Read in a process to decode the strange quotes\ntext = f.read().decode('utf-8')\n\n# Substitute decoded quotes with regular single quotes\nimport re\ntext = re.sub('\\u2019|\\u201c|\\u201d', \"'\", text).replace('\\n', ' ')\ntext = text.encode('utf-8')", "outputs": [], "metadata": {"collapsed": false}}, {"source": "You can also try some of your own text either in a file or a string literal in a code cell here.", "cell_type": "markdown", "metadata": {}}, {"source": "**Set up the header and parameter part of request**\n\nOur content type is `'text/plain'` this time.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# grab key from json in config\nsubscription_key = keys['proper key name']\n\n# http headers needed for POST request\n# we keep these as dict\nheaders = {\n    # Request headers - note content type is text/plain!\n    'Content-Type': 'text/plain',\n    'Ocp-Apim-Subscription-Key': subscription_key,\n}\n\n# params will be added to POST in url request\n# right now it's empty because for this request we don't need any params\n# although we could have included 'selection' and 'offset' - see docs\nparams = urlencode({})", "outputs": [], "metadata": {"collapsed": false}}, {"source": "**Make the API request call**\n\nGiven a specific paragraph of text within a document, the Entity Linking Intelligence Service will recognize and identify each separate entity based on the context", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "try:\n    conn = HTTPSConnection('api.projectoxford.ai')\n    \n    # Post method request - note:  body of request is converted from json to string\n    conn.request(\"POST\", \"/entitylinking/v1.0/link?%s\" % params, body = text, headers = headers)\n    response = conn.getresponse()\n    data = response.read()\n    conn.close()\nexcept Exception as e:\n    print(\"[Error: {0}] \".format(e))\n    \n# Print the results - json response format\nprint(json.dumps(json.loads(data), \n           sort_keys=True,\n           indent=4, \n           separators=(',', ': ')))", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.11", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}